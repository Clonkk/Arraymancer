<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>Arraymancer - Tutorial: First steps</title>

  <link href="docutils.css" rel="stylesheet" type="text/css"/>
  <link href="nav.css" rel="stylesheet" type="text/css"/>

  <link href='http://fonts.googleapis.com/css?family=Raleway:400,600,900' rel='stylesheet' type='text/css'/>
  <link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:400,500,600' rel='stylesheet' type='text/css'/>
</head>
<body>
<a href="https://github.com/mratsim/arraymancer"><img style="position: fixed; top: 0; right: 0; border: 0; z-index: 10;" src="https://camo.githubusercontent.com/652c5b9acfaddf3a9c326fa6bde407b87f7be0f4/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6f72616e67655f6666373630302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_orange_ff7600.png"></a>
<header>
  <a class="pagetitle" href="index.html">Arraymancer</a>
  <span>
    <a href="#">Technical reference</a>
    <ul class="monospace">
      <span>
        <a href="#">Core tensor API</a>
        <ul class="monospace">
          <li><a href="tensor.accessors_macros_read.html">tensor.accessors_macros_read</a></li>
          <li><a href="tensor.accessors_macros_syntax.html">tensor.accessors_macros_syntax</a></li>
          <li><a href="tensor.accessors_macros_write.html">tensor.accessors_macros_write</a></li>
          <li><a href="tensor.accessors.html">tensor.accessors</a></li>
          <li><a href="tensor.aggregate.html">tensor.aggregate</a></li>
          <li><a href="tensor.comparison.html">tensor.comparison</a></li>
          <li><a href="tensor.data_structure.html">tensor.data_structure</a></li>
          <li><a href="tensor.display.html">tensor.display</a></li>
          <li><a href="tensor.display_cuda.html">tensor.display_cuda</a></li>
          <li><a href="tensor.exporting.html">tensor.exporting</a></li>
          <li><a href="tensor.filling_data.html">tensor.filling_data</a></li>
          <li><a href="tensor.higher_order_applymap.html">tensor.higher_order_applymap</a></li>
          <li><a href="tensor.higher_order_foldreduce.html">tensor.higher_order_foldreduce</a></li>
          <li><a href="tensor.init_cpu.html">tensor.init_cpu</a></li>
          <li><a href="tensor.init_cuda.html">tensor.init_cuda</a></li>
          <li><a href="tensor.init_opencl.html">tensor.init_opencl</a></li>
          <li><a href="tensor.init_copy_cpu.html">tensor.init_copy_cpu</a></li>
          <li><a href="tensor.init_copy_cuda.html">tensor.init_copy_cuda</a></li>
          <li><a href="tensor.lapack.html">tensor.lapack</a></li>
          <li><a href="tensor.math_functions.html">tensor.math_functions</a></li>
          <li><a href="tensor.operators_blas_l1.html">tensor.operators_blas_l1</a></li>
          <li><a href="tensor.operators_blas_l1_cuda.html">tensor.operators_blas_l1_cuda</a></li>
          <li><a href="tensor.operators_blas_l1_opencl.html">tensor.operators_blas_l1_opencl</a></li>
          <li><a href="tensor.operators_blas_l2l3.html">tensor.operators_blas_l2l3</a></li>
          <li><a href="tensor.operators_blas_l2l3_cuda.html">tensor.operators_blas_l2l3_cuda</a></li>
          <li><a href="tensor.operators_blas_l2l3_opencl.html">tensor.operators_blas_l2l3_opencl</a></li>
          <li><a href="tensor.operators_broadcasted.html">tensor.operators_broadcasted</a></li>
          <li><a href="tensor.operators_broadcasted_cuda.html">tensor.operators_broadcasted_cuda</a></li>
          <li><a href="tensor.operators_broadcasted_opencl.html">tensor.operators_broadcasted_opencl</a></li>
          <li><a href="tensor.operators_comparison.html">tensor.operators_comparison</a></li>
          <li><a href="tensor.operators_logical.html">tensor.operators_logical</a></li>
          <li><a href="tensor.optim_ops_fusion.html">tensor.optim_ops_fusion</a></li>
          <li><a href="tensor.shapeshifting.html">tensor.shapeshifting</a></li>
          <li><a href="tensor.shapeshifting_cuda.html">tensor.shapeshifting_cuda</a></li>
          <li><a href="tensor.shapeshifting_opencl.html">tensor.shapeshifting_opencl</a></li>
          <li><a href="tensor.syntactic_sugar.html">tensor.syntactic_sugar</a></li>
          <li><a href="tensor.ufunc.html">tensor.ufunc</a></li>
        </ul>
      </span>
      <span>
        <a href="#">Neural network API</a>
        <ul class="monospace">
          <li><a href="nn_dsl.dsl_core.html">Neural network: Declaration</a></li>
          <li><a href="nn_activation.relu.html">Activation: Relu (Rectified linear Unit)</a></li>
          <li><a href="nn_activation.sigmoid.html">Activation: Sigmoid</a></li>
          <li><a href="nn_activation.tanh.html">Activation: Tanh</a></li>
          <li><a href="nn_layers.conv2D.html">Layers: Convolution 2D</a></li>
          <li><a href="nn_layers.embedding.html">Layers: Embedding</a></li>
          <li><a href="nn_layers.gru.html">Layers: GRU (Gated Linear Unit)</a></li>
          <li><a href="nn_layers.linear.html">Layers: Linear/Dense</a></li>
          <li><a href="nn_layers.maxpool2D.html">Layers: Maxpool 2D</a></li>
          <li><a href="nn_loss.cross_entropy_losses.html">Loss: Cross-Entropy losses</a></li>
          <li><a href="nn_loss.mean_square_error_loss.html">Loss: Mean Square Error</a></li>
          <li><a href="nn_optimizers.optimizers.html">Optimizers</a></li>
          <li><a href="nn_shapeshifting.reshape_flatten.html">Reshape & Flatten</a></li>
        </ul>
      </span>
      <span>
        <a href="#">Linear algebra, stats, ML</a>
        <ul class="monospace">
          <li><a href="la.decomposition.html">Eigenvalue decomposition</a></li>
          <li><a href="la.least_squares.html">Least Squares solver</a></li>
          <li><a href="stats.stats.html">Statistics</a></li>
          <li><a href="ml.pca.html">Principal Component Analysis (PCA)</a></li>
          <li><a href="ml.accuracy_score.html">Accuracy score</a></li>
          <li><a href="ml.common_error_functions.html">Common errors, MAE and MSE (L1, L2 loss)</a></li>
        </ul>
      </span>
      <span>
        <a href="#">IO & Datasets</a>
        <ul class="monospace">
          <li><a href="datasets.mnist.html">MNIST</a></li>
          <li><a href="datasets.imdb.html">IMDB</a></li>
          <li><a href="io.io_csv.html">CSV reading and writing</a></li>
          <li><a href="io.io_hdf5.html">HDF5 files reading and writing</a></li>
          <li><a href="io.io_image.html">Images reading and writing</a></li>
          <li><a href="io.io_npy.html">Numpy files reading and writing</a></li>
        </ul>
      </span>
      <span>
        <a href="#">Autograd</a>
        <ul class="monospace">
          <li><a href="ag.ag_accessors.html">Accessors</a></li>
          <li><a href="ag.ag_data_structure.html">Data structure</a></li>
          <li><a href="ag.gates_basic.html">Basic operations</a></li>
          <li><a href="ag.gates_blas.html">Linear algebra operations</a></li>
          <li><a href="ag.gates_hadamard.html">Hadamard product (elementwise matrix multiply)</a></li>
          <li><a href="ag.gates_reduce.html">Reduction operations</a></li>
          <li><a href="ag.gates_shapeshifting_concat_split.html">Concatenation, stacking, splitting, chunking operations</a></li>
          <li><a href="ag.gates_shapeshifting_views.html">Linear algebra operations</a></li>
        </ul>
      </span>
      <span>
        <a href="#">Neuralnet primitives</a>
        <ul class="monospace">
          <li><a href="nnp.nnp_activation.html">Activations</a></li>
          <li><a href="nnp.nnp_convolution.html">Convolution 2D</a></li>
          <li><a href="nnp.nnp_conv2D_cudnn.html">Convolution 2D - CuDNN</a></li>
          <li><a href="nnp.nnp_embedding.html">Linear / Dense layer</a></li>
          <li><a href="nnp.nnp_gru.html">Linear / Dense layer</a></li>
          <li><a href="nnp.nnp_linear.html">Linear / Dense layer</a></li>
          <li><a href="nnp.nnp_maxpooling.html">Maxpooling</a></li>
          <li><a href="nnp.nnp_numerical_gradient.html">Numerical gradient</a></li>
          <li><a href="nnp.nnp_sigmoid_cross_entropy.html">Sigmoid Cross-Entropy loss</a></li>
          <li><a href="nnp.nnp_softmax_cross_entropy.html">Softmax Cross-Entropy loss</a></li>
          <li><a href="nnp.nnp_softmax.html">Softmax</a></li>
        </ul>
      </span>
    </ul>
  </span>
  <span>
    <a href="#">Tutorial</a>
    <ul class="monospace">
      <li><a href="tuto.first_steps.html">First steps</a></li>
      <li><a href="tuto.slicing.html">Taking a slice of a tensor</a></li>
      <li><a href="tuto.linear_algebra.html">Matrix & vectors operations</a></li>
      <li><a href="tuto.broadcasting.html">Broadcasted operations</a></li>
      <li><a href="tuto.shapeshifting.html">Transposing, Reshaping, Permuting, Concatenating</a></li>
      <li><a href="tuto.map_reduce.html">Map & Reduce</a></li>
      <li><a href="tuto.iterators.html">Basic iterators</a></li>
    </ul>
  </span>
  <span>
    <a href="#">Spellbook (How-To&apos;s)</a>
    <ul class="monospace">
      <li><a href="howto.type_conversion.html">How to convert a Tensor type?</a></li>
      <li><a href="howto.ufunc.html">How to create a new universal function?</a></li>
      <li><a href="howto.perceptron.html">How to create a multilayer perceptron?</a></li>
    </ul>
  </span>
  <span>
    <a href="#">Under the hood</a>
    <ul class="monospace">
      <li><a href="uth.speed.html">How Arraymancer achieves its speed?</a></li>
      <li><a href="uth.copy_semantics.html">Why does `=` share data by default aka reference semantics?</a></li>
      <li><a href="uth.opencl_cuda_nim.html">Working with OpenCL and Cuda in Nim</a></li>
    </ul>
  </span>
</header>
<article id="documentId">
  <div class="container">
    <h1 class="title">Tutorial: First steps</h1>
    
<h1 id="tensor-properties">Tensor properties</h1><p>Tensors have the following properties: - <tt class="docutils literal"><span class="pre">rank</span></tt>: - 0 for scalar (unfortunately cannot be stored) - 1 for vector - 2 for matrices - N for N-dimension array - <tt class="docutils literal"><span class="pre">shape</span></tt>: a sequence of the tensor dimensions along each axis.</p>
<p>Next properties are technical and there for completeness - <tt class="docutils literal"><span class="pre">strides</span></tt>: a sequence of numbers of steps to get the next item along a dimension. - <tt class="docutils literal"><span class="pre">offset</span></tt>: the first element of the tensor</p>
<pre class="listing"><span class="Keyword">import</span> <span class="Identifier">arraymancer</span>

<span class="Keyword">let</span> <span class="Identifier">d</span> <span class="Operator">=</span> <span class="Punctuation">[</span><span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">2</span><span class="Punctuation">,</span> <span class="DecNumber">3</span><span class="Punctuation">]</span><span class="Punctuation">,</span> <span class="Punctuation">[</span><span class="DecNumber">4</span><span class="Punctuation">,</span> <span class="DecNumber">5</span><span class="Punctuation">,</span> <span class="DecNumber">6</span><span class="Punctuation">]</span><span class="Punctuation">]</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Punctuation">)</span>

<span class="Identifier">echo</span> <span class="Identifier">d</span>
<span class="Comment"># Tensor of shape 2x3 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |1      2       3|</span>
<span class="Comment"># |4      5       6|</span>

<span class="Identifier">echo</span> <span class="Identifier">d</span><span class="Operator">.</span><span class="Identifier">rank</span> <span class="Comment"># 2</span>
<span class="Identifier">echo</span> <span class="Identifier">d</span><span class="Operator">.</span><span class="Identifier">shape</span> <span class="Comment"># @[2, 3]</span>
<span class="Identifier">echo</span> <span class="Identifier">d</span><span class="Operator">.</span><span class="Identifier">strides</span> <span class="Comment"># @[3, 1] =&gt; Next row is 3 elements away in memory while next column is 1 element away.</span>
<span class="Identifier">echo</span> <span class="Identifier">d</span><span class="Operator">.</span><span class="Identifier">offset</span> <span class="Comment"># 0</span></pre>
<h1 id="tensor-creation">Tensor creation</h1><p>The canonical way to initialize a tensor is by converting a seq of seq of … or an array of array of … into a tensor using <tt class="docutils literal"><span class="pre">toTensor</span></tt>.</p>
<p><tt class="docutils literal"><span class="pre">toTensor</span></tt> supports deep nested sequences and arrays, even sequence of arrays of sequences.</p>
<pre class="listing"><span class="Keyword">import</span> <span class="Identifier">arraymancer</span>

<span class="Keyword">let</span> <span class="Identifier">c</span> <span class="Operator">=</span> <span class="Punctuation">[</span>
          <span class="Punctuation">[</span>
            <span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">,</span><span class="DecNumber">2</span><span class="Punctuation">,</span><span class="DecNumber">3</span><span class="Punctuation">]</span><span class="Punctuation">,</span>
            <span class="Punctuation">[</span><span class="DecNumber">4</span><span class="Punctuation">,</span><span class="DecNumber">5</span><span class="Punctuation">,</span><span class="DecNumber">6</span><span class="Punctuation">]</span>
          <span class="Punctuation">]</span><span class="Punctuation">,</span>
          <span class="Punctuation">[</span>
            <span class="Punctuation">[</span><span class="DecNumber">11</span><span class="Punctuation">,</span><span class="DecNumber">22</span><span class="Punctuation">,</span><span class="DecNumber">33</span><span class="Punctuation">]</span><span class="Punctuation">,</span>
            <span class="Punctuation">[</span><span class="DecNumber">44</span><span class="Punctuation">,</span><span class="DecNumber">55</span><span class="Punctuation">,</span><span class="DecNumber">66</span><span class="Punctuation">]</span>
          <span class="Punctuation">]</span><span class="Punctuation">,</span>
          <span class="Punctuation">[</span>
            <span class="Punctuation">[</span><span class="DecNumber">111</span><span class="Punctuation">,</span><span class="DecNumber">222</span><span class="Punctuation">,</span><span class="DecNumber">333</span><span class="Punctuation">]</span><span class="Punctuation">,</span>
            <span class="Punctuation">[</span><span class="DecNumber">444</span><span class="Punctuation">,</span><span class="DecNumber">555</span><span class="Punctuation">,</span><span class="DecNumber">666</span><span class="Punctuation">]</span>
          <span class="Punctuation">]</span><span class="Punctuation">,</span>
          <span class="Punctuation">[</span>
            <span class="Punctuation">[</span><span class="DecNumber">1111</span><span class="Punctuation">,</span><span class="DecNumber">2222</span><span class="Punctuation">,</span><span class="DecNumber">3333</span><span class="Punctuation">]</span><span class="Punctuation">,</span>
            <span class="Punctuation">[</span><span class="DecNumber">4444</span><span class="Punctuation">,</span><span class="DecNumber">5555</span><span class="Punctuation">,</span><span class="DecNumber">6666</span><span class="Punctuation">]</span>
          <span class="Punctuation">]</span>
        <span class="Punctuation">]</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Punctuation">)</span>
<span class="Identifier">echo</span> <span class="Identifier">c</span>

<span class="Comment"># Tensor of shape 4x2x3 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment">#  |      1       2       3 |     11      22      33 |    111     222     333 |   1111    2222    3333|</span>
<span class="Comment">#  |      4       5       6 |     44      55      66 |    444     555     666 |   4444    5555    6666|</span></pre><p><tt class="docutils literal"><span class="pre">newTensor</span></tt> procedure can be used to initialize a tensor of a specific shape with a default value. (0 for numbers, false for bool …)</p>
<p><tt class="docutils literal"><span class="pre">zeros</span></tt> and <tt class="docutils literal"><span class="pre">ones</span></tt> procedures create a new tensor filled with 0 and 1 respectively.</p>
<p><tt class="docutils literal"><span class="pre">zeros_like</span></tt> and <tt class="docutils literal"><span class="pre">ones_like</span></tt> take an input tensor and output a tensor of the same shape but filled with 0 and 1 respectively.</p>
<pre class="listing"><span class="Keyword">let</span> <span class="Identifier">e</span> <span class="Operator">=</span> <span class="Identifier">newTensor</span><span class="Punctuation">[</span><span class="Identifier">bool</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="Punctuation">[</span><span class="DecNumber">2</span><span class="Punctuation">,</span> <span class="DecNumber">3</span><span class="Punctuation">]</span><span class="Punctuation">)</span>
<span class="Comment"># Tensor of shape 2x3 of type &quot;bool&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |false  false   false|</span>
<span class="Comment"># |false  false   false|</span>

<span class="Keyword">let</span> <span class="Identifier">f</span> <span class="Operator">=</span> <span class="Identifier">zeros</span><span class="Punctuation">[</span><span class="Identifier">float</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="Punctuation">[</span><span class="DecNumber">4</span><span class="Punctuation">,</span> <span class="DecNumber">3</span><span class="Punctuation">]</span><span class="Punctuation">)</span>
<span class="Comment"># Tensor of shape 4x3 of type &quot;float&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |0.0    0.0     0.0|</span>
<span class="Comment"># |0.0    0.0     0.0|</span>
<span class="Comment"># |0.0    0.0     0.0|</span>
<span class="Comment"># |0.0    0.0     0.0|</span>

<span class="Keyword">let</span> <span class="Identifier">g</span> <span class="Operator">=</span> <span class="Identifier">ones</span><span class="Punctuation">[</span><span class="Identifier">float</span><span class="Punctuation">]</span><span class="Punctuation">(</span><span class="Punctuation">[</span><span class="DecNumber">4</span><span class="Punctuation">,</span> <span class="DecNumber">3</span><span class="Punctuation">]</span><span class="Punctuation">)</span>
<span class="Comment"># Tensor of shape 4x3 of type &quot;float&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |1.0    1.0     1.0|</span>
<span class="Comment"># |1.0    1.0     1.0|</span>
<span class="Comment"># |1.0    1.0     1.0|</span>
<span class="Comment"># |1.0    1.0     1.0|</span>

<span class="Keyword">let</span> <span class="Identifier">tmp</span> <span class="Operator">=</span> <span class="Punctuation">[</span><span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">,</span><span class="DecNumber">2</span><span class="Punctuation">]</span><span class="Punctuation">,</span><span class="Punctuation">[</span><span class="DecNumber">3</span><span class="Punctuation">,</span><span class="DecNumber">4</span><span class="Punctuation">]</span><span class="Punctuation">]</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Punctuation">)</span>
<span class="Keyword">let</span> <span class="Identifier">h</span> <span class="Operator">=</span> <span class="Identifier">tmp</span><span class="Operator">.</span><span class="Identifier">zeros_like</span>
<span class="Comment"># Tensor of shape 2x2 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |0      0|</span>
<span class="Comment"># |0      0|</span>

<span class="Keyword">let</span> <span class="Identifier">i</span> <span class="Operator">=</span> <span class="Identifier">tmp</span><span class="Operator">.</span><span class="Identifier">ones_like</span>
<span class="Comment"># Tensor of shape 2x2 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment"># |1      1|</span>
<span class="Comment"># |1      1|</span></pre>
<h1 id="accessing-and-modifying-a-value">Accessing and modifying a value</h1><p>Tensors value can be retrieved or set with array brackets.</p>
<pre class="listing"><span class="Keyword">var</span> <span class="Identifier">a</span> <span class="Operator">=</span> <span class="Identifier">toSeq</span><span class="Punctuation">(</span><span class="FloatNumber">1.</span><span class="Operator">.</span><span class="DecNumber">24</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">reshape</span><span class="Punctuation">(</span><span class="DecNumber">2</span><span class="Punctuation">,</span><span class="DecNumber">3</span><span class="Punctuation">,</span><span class="DecNumber">4</span><span class="Punctuation">)</span>

<span class="Identifier">echo</span> <span class="Identifier">a</span>
<span class="Comment"># Tensor of shape 2x3x4 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment">#  |      1       2       3       4 |     13      14      15      16|</span>
<span class="Comment">#  |      5       6       7       8 |     17      18      19      20|</span>
<span class="Comment">#  |      9       10      11      12 |    21      22      23      24|</span>

<span class="Identifier">echo</span> <span class="Identifier">a</span><span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">1</span><span class="Punctuation">]</span>
<span class="Comment"># 18</span>

<span class="Identifier">a</span><span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">1</span><span class="Punctuation">]</span> <span class="Operator">=</span> <span class="DecNumber">999</span>
<span class="Identifier">echo</span> <span class="Identifier">a</span>
<span class="Comment"># Tensor of shape 2x3x4 of type &quot;int&quot; on backend &quot;Cpu&quot;</span>
<span class="Comment">#  |      1       2       3       4 |     13      14      15      16|</span>
<span class="Comment">#  |      5       6       7       8 |     17      999     19      20|</span>
<span class="Comment">#  |      9       10      11      12 |    21      22      23      24|</span></pre>
<h1 id="copying">Copying</h1><p>Warning ⚠: When you do the following, both tensors <tt class="docutils literal"><span class="pre">a</span></tt> and <tt class="docutils literal"><span class="pre">b</span></tt> will share data. Full copy must be explicitly requested via the <tt class="docutils literal"><span class="pre">clone</span></tt> function.</p>
<pre class="listing"><span class="Keyword">let</span> <span class="Identifier">a</span> <span class="Operator">=</span> <span class="Identifier">toSeq</span><span class="Punctuation">(</span><span class="FloatNumber">1.</span><span class="Operator">.</span><span class="DecNumber">24</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">toTensor</span><span class="Punctuation">(</span><span class="Punctuation">)</span><span class="Operator">.</span><span class="Identifier">reshape</span><span class="Punctuation">(</span><span class="DecNumber">2</span><span class="Punctuation">,</span><span class="DecNumber">3</span><span class="Punctuation">,</span><span class="DecNumber">4</span><span class="Punctuation">)</span>
<span class="Keyword">var</span> <span class="Identifier">b</span> <span class="Operator">=</span> <span class="Identifier">a</span></pre><p>Here modifying <tt class="docutils literal"><span class="pre">b</span></tt> WILL modify <tt class="docutils literal"><span class="pre">a</span></tt>. This behaviour is the same as Numpy and Julia, reasons can be found in the following <a class="reference external" href="https://mratsim.github.io/Arraymancer/uth.copy_semantics.html">under the hood article</a>.</p>



    <div class="row">
      <div class="twelve-columns footer">
        <span class="nim-sprite"></span>
        <br/>
        <small>Made with Nim. Generated: 2018-12-23 21:51:53 UTC</small>
      </div>
    </div>
  </div>
</article>
</body>
</html>
