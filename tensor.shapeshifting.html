<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>Arraymancer - shapeshifting</title>

  <link href="docutils.css" rel="stylesheet" type="text/css"/>
  <link href="nav.css" rel="stylesheet" type="text/css"/>

  <link href='http://fonts.googleapis.com/css?family=Raleway:400,600,900' rel='stylesheet' type='text/css'/>
  <link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:400,500,600' rel='stylesheet' type='text/css'/>
</head>
<body>
<a href="https://github.com/mratsim/arraymancer"><img style="position: fixed; top: 0; right: 0; border: 0; z-index: 10;" src="https://camo.githubusercontent.com/652c5b9acfaddf3a9c326fa6bde407b87f7be0f4/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6f72616e67655f6666373630302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_orange_ff7600.png"></a>
<header>
  <a class="pagetitle" href="index.html">Arraymancer</a>
  <span>
    <a href="#">Technical reference</a>
    <ul class="monospace">
      <span>
        <a href="#">Core tensor API</a>
        <ul class="monospace">
          <li><a href="tensor.accessors_macros_read.html">tensor.accessors_macros_read</a></li>
          <li><a href="tensor.accessors_macros_syntax.html">tensor.accessors_macros_syntax</a></li>
          <li><a href="tensor.accessors_macros_write.html">tensor.accessors_macros_write</a></li>
          <li><a href="tensor.accessors.html">tensor.accessors</a></li>
          <li><a href="tensor.aggregate.html">tensor.aggregate</a></li>
          <li><a href="tensor.comparison.html">tensor.comparison</a></li>
          <li><a href="tensor.data_structure.html">tensor.data_structure</a></li>
          <li><a href="tensor.display.html">tensor.display</a></li>
          <li><a href="tensor.display_cuda.html">tensor.display_cuda</a></li>
          <li><a href="tensor.exporting.html">tensor.exporting</a></li>
          <li><a href="tensor.filling_data.html">tensor.filling_data</a></li>
          <li><a href="tensor.higher_order_applymap.html">tensor.higher_order_applymap</a></li>
          <li><a href="tensor.higher_order_foldreduce.html">tensor.higher_order_foldreduce</a></li>
          <li><a href="tensor.init_cpu.html">tensor.init_cpu</a></li>
          <li><a href="tensor.init_cuda.html">tensor.init_cuda</a></li>
          <li><a href="tensor.init_opencl.html">tensor.init_opencl</a></li>
          <li><a href="tensor.init_copy_cpu.html">tensor.init_copy_cpu</a></li>
          <li><a href="tensor.init_copy_cuda.html">tensor.init_copy_cuda</a></li>
          <li><a href="tensor.lapack.html">tensor.lapack</a></li>
          <li><a href="tensor.math_functions.html">tensor.math_functions</a></li>
          <li><a href="tensor.operators_blas_l1.html">tensor.operators_blas_l1</a></li>
          <li><a href="tensor.operators_blas_l1_cuda.html">tensor.operators_blas_l1_cuda</a></li>
          <li><a href="tensor.operators_blas_l1_opencl.html">tensor.operators_blas_l1_opencl</a></li>
          <li><a href="tensor.operators_blas_l2l3.html">tensor.operators_blas_l2l3</a></li>
          <li><a href="tensor.operators_blas_l2l3_cuda.html">tensor.operators_blas_l2l3_cuda</a></li>
          <li><a href="tensor.operators_blas_l2l3_opencl.html">tensor.operators_blas_l2l3_opencl</a></li>
          <li><a href="tensor.operators_broadcasted.html">tensor.operators_broadcasted</a></li>
          <li><a href="tensor.operators_broadcasted_cuda.html">tensor.operators_broadcasted_cuda</a></li>
          <li><a href="tensor.operators_broadcasted_opencl.html">tensor.operators_broadcasted_opencl</a></li>
          <li><a href="tensor.operators_comparison.html">tensor.operators_comparison</a></li>
          <li><a href="tensor.operators_logical.html">tensor.operators_logical</a></li>
          <li><a href="tensor.optim_ops_fusion.html">tensor.optim_ops_fusion</a></li>
          <li><a href="tensor.shapeshifting.html">tensor.shapeshifting</a></li>
          <li><a href="tensor.shapeshifting_cuda.html">tensor.shapeshifting_cuda</a></li>
          <li><a href="tensor.shapeshifting_opencl.html">tensor.shapeshifting_opencl</a></li>
          <li><a href="tensor.syntactic_sugar.html">tensor.syntactic_sugar</a></li>
          <li><a href="tensor.ufunc.html">tensor.ufunc</a></li>
        </ul>
      </span>
      <span>
        <a href="#">Neural network API</a>
        <ul class="monospace">
          <li><a href="nn_dsl.dsl_core.html">Neural network: Declaration</a></li>
          <li><a href="nn_activation.relu.html">Activation: Relu (Rectified linear Unit)</a></li>
          <li><a href="nn_activation.sigmoid.html">Activation: Sigmoid</a></li>
          <li><a href="nn_activation.tanh.html">Activation: Tanh</a></li>
          <li><a href="nn_layers.conv2D.html">Layers: Convolution 2D</a></li>
          <li><a href="nn_layers.embedding.html">Layers: Embedding</a></li>
          <li><a href="nn_layers.gru.html">Layers: GRU (Gated Linear Unit)</a></li>
          <li><a href="nn_layers.linear.html">Layers: Linear/Dense</a></li>
          <li><a href="nn_layers.maxpool2D.html">Layers: Maxpool 2D</a></li>
          <li><a href="nn_loss.cross_entropy_losses.html">Loss: Cross-Entropy losses</a></li>
          <li><a href="nn_loss.mean_square_error_loss.html">Loss: Mean Square Error</a></li>
          <li><a href="nn_optimizers.optimizers.html">Optimizers</a></li>
          <li><a href="nn_shapeshifting.reshape_flatten.html">Reshape & Flatten</a></li>
        </ul>
      </span>
      <span>
        <a href="#">Linear algebra, stats, ML</a>
        <ul class="monospace">
          <li><a href="la.decomposition.html">Eigenvalue decomposition</a></li>
          <li><a href="la.decomposition_rand.html">Randomized Truncated SVD</a></li>
          <li><a href="la.least_squares.html">Least squares solver</a></li>
          <li><a href="la.linear_systems.html">Linear systems solver</a></li>
          <li><a href="la.special_matrices.html">Special linear algebra matrices</a></li>
          <li><a href="stats.stats.html">Statistics</a></li>
          <li><a href="ml.pca.html">Principal Component Analysis (PCA)</a></li>
          <li><a href="ml.accuracy_score.html">Accuracy score</a></li>
          <li><a href="ml.common_error_functions.html">Common errors, MAE and MSE (L1, L2 loss)</a></li>
          <li><a href="ml.kmeans.html">K-Means</a></li>
        </ul>
      </span>
      <span>
        <a href="#">IO & Datasets</a>
        <ul class="monospace">
          <li><a href="datasets.mnist.html">MNIST</a></li>
          <li><a href="datasets.imdb.html">IMDB</a></li>
          <li><a href="io.io_csv.html">CSV reading and writing</a></li>
          <li><a href="io.io_hdf5.html">HDF5 files reading and writing</a></li>
          <li><a href="io.io_image.html">Images reading and writing</a></li>
          <li><a href="io.io_npy.html">Numpy files reading and writing</a></li>
        </ul>
      </span>
      <span>
        <a href="#">Autograd</a>
        <ul class="monospace">
          <li><a href="ag.autograd_common.html">Data structure</a></li>
          <li><a href="ag.gates_basic.html">Basic operations</a></li>
          <li><a href="ag.gates_blas.html">Linear algebra operations</a></li>
          <li><a href="ag.gates_hadamard.html">Hadamard product (elementwise matrix multiply)</a></li>
          <li><a href="ag.gates_reduce.html">Reduction operations</a></li>
          <li><a href="ag.gates_shapeshifting_concat_split.html">Concatenation, stacking, splitting, chunking operations</a></li>
          <li><a href="ag.gates_shapeshifting_views.html">Linear algebra operations</a></li>
        </ul>
      </span>
      <span>
        <a href="#">Neuralnet primitives</a>
        <ul class="monospace">
          <li><a href="nnp.nnp_activation.html">Activations</a></li>
          <li><a href="nnp.nnp_convolution.html">Convolution 2D</a></li>
          <li><a href="nnp.nnp_conv2d_cudnn.html">Convolution 2D - CuDNN</a></li>
          <li><a href="nnp.nnp_embedding.html">Embeddings</a></li>
          <li><a href="nnp.nnp_gru.html">Gated Recurrent Unit (GRU)</a></li>
          <li><a href="nnp.nnp_linear.html">Linear / Dense layer</a></li>
          <li><a href="nnp.nnp_maxpooling.html">Maxpooling</a></li>
          <li><a href="nnp.nnp_numerical_gradient.html">Numerical gradient</a></li>
          <li><a href="nnp.nnp_sigmoid_cross_entropy.html">Sigmoid Cross-Entropy loss</a></li>
          <li><a href="nnp.nnp_softmax_cross_entropy.html">Softmax Cross-Entropy loss</a></li>
          <li><a href="nnp.nnp_softmax.html">Softmax</a></li>
        </ul>
      </span>
    </ul>
  </span>
  <span>
    <a href="#">Tutorial</a>
    <ul class="monospace">
      <li><a href="tuto.first_steps.html">First steps</a></li>
      <li><a href="tuto.slicing.html">Taking a slice of a tensor</a></li>
      <li><a href="tuto.linear_algebra.html">Matrix & vectors operations</a></li>
      <li><a href="tuto.broadcasting.html">Broadcasted operations</a></li>
      <li><a href="tuto.shapeshifting.html">Transposing, Reshaping, Permuting, Concatenating</a></li>
      <li><a href="tuto.map_reduce.html">Map & Reduce</a></li>
      <li><a href="tuto.iterators.html">Basic iterators</a></li>
    </ul>
  </span>
  <span>
    <a href="#">Spellbook (How-To&apos;s)</a>
    <ul class="monospace">
      <li><a href="howto.type_conversion.html">How to convert a Tensor type?</a></li>
      <li><a href="howto.ufunc.html">How to create a new universal function?</a></li>
      <li><a href="howto.perceptron.html">How to create a multilayer perceptron?</a></li>
    </ul>
  </span>
  <span>
    <a href="#">Under the hood</a>
    <ul class="monospace">
      <li><a href="uth.speed.html">How Arraymancer achieves its speed?</a></li>
      <li><a href="uth.copy_semantics.html">Why does `=` share data by default aka reference semantics?</a></li>
      <li><a href="uth.opencl_cuda_nim.html">Working with OpenCL and Cuda in Nim</a></li>
    </ul>
  </span>
</header>
<article id="documentId">
  <div class="container">
    <h1 class="title">shapeshifting</h1>
    <div class="row">
  <div class="three columns">
  <div id="global-links">
    <ul class="simple">
    </ul>
  </div>
  <div id="searchInputDiv">
    Search: <input type="text" id="searchInput"
      onkeyup="search()" />
  </div>
  <div>
    Group by:
    <select onchange="groupBy(this.value)">
      <option value="section">Section</option>
      <option value="type">Type</option>
    </select>
  </div>
  <ul class="simple simple-toc" id="toc-list">
<li>
  <a class="reference reference-toplevel" href="#6" id="56">Imports</a>
  <ul class="simple simple-toc-section">

  </ul>
</li>
<li>
  <a class="reference reference-toplevel" href="#12" id="62">Procs</a>
  <ul class="simple simple-toc-section">
      <li><a class="reference" href="#transpose%2CTensor"
    title="transpose(t: Tensor): Tensor"><wbr />transpose<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#asContiguous%2CTensor%5BT%5D%2COrderType%2Cbool"
    title="asContiguous[T](t: Tensor[T]; layout: OrderType = rowMajor; force: bool = false): Tensor[T]"><wbr />as<wbr />Contiguous<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#reshape%2CTensor%2Cvarargs%5Bint%5D"
    title="reshape(t: Tensor; new_shape: varargs[int]): Tensor"><wbr />reshape<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#reshape%2CTensor%2CMetadataArray"
    title="reshape(t: Tensor; new_shape: MetadataArray): Tensor"><wbr />reshape<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#broadcast%2CTensor%5BT%5D%2Cvarargs%5Bint%5D"
    title="broadcast[T](t: Tensor[T]; shape: varargs[int]): Tensor[T]"><wbr />broadcast<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#broadcast%2CTensor%5BT%5D%2CMetadataArray"
    title="broadcast[T](t: Tensor[T]; shape: MetadataArray): Tensor[T]"><wbr />broadcast<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#broadcast%2CT%2Cvarargs%5Bint%5D"
    title="broadcast[T: SomeNumber](val: T; shape: varargs[int]): Tensor[T]"><wbr />broadcast<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#broadcast%2CT%2CMetadataArray"
    title="broadcast[T: SomeNumber](val: T; shape: MetadataArray): Tensor[T]"><wbr />broadcast<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#broadcast2%2CTensor%5BT%5D%2CTensor%5BT%5D"
    title="broadcast2[T](a, b: Tensor[T]): tuple[a, b: Tensor[T]]"><wbr />broadcast2<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#permute%2CTensor%2Cvarargs%5Bint%5D"
    title="permute(t: Tensor; dims: varargs[int]): Tensor"><wbr />permute<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#concat%2Cvarargs%5BTensor%5BT%5D%5D%2Cint"
    title="concat[T](t_list: varargs[Tensor[T]]; axis: int): Tensor[T]"><wbr />concat<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#stack%2Cvarargs%5BTensor%5BT%5D%5D%2CNatural"
    title="stack[T](tensors: varargs[Tensor[T]]; axis: Natural = 0): Tensor[T]"><wbr />stack<span class="attachedType"></span></a></li>

  </ul>
</li>
<li>
  <a class="reference reference-toplevel" href="#13" id="63">Funcs</a>
  <ul class="simple simple-toc-section">
      <li><a class="reference" href="#squeeze%2CAnyTensor"
    title="squeeze(t: AnyTensor): AnyTensor"><wbr />squeeze<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#squeeze%2CTensor%2CNatural"
    title="squeeze(t: Tensor; axis: Natural): Tensor"><wbr />squeeze<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#unsqueeze%2CTensor%2CNatural"
    title="unsqueeze(t: Tensor; axis: Natural): Tensor"><wbr />unsqueeze<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#split%2CTensor%5BT%5D%2CPositive%2CNatural"
    title="split[T](t: Tensor[T]; chunk_size: Positive; axis: Natural): seq[Tensor[T]]"><wbr />split<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#chunk%2CTensor%5BT%5D%2CPositive%2CNatural"
    title="chunk[T](t: Tensor[T]; nb_chunks: Positive; axis: Natural): seq[Tensor[T]]"><wbr />chunk<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#index_select%2CTensor%5BT%5D%2Cint%2CTensor%5BIdx%3A+byte+or+char+or+int+or+int8+or+int16+or+int32+or+int64+or+uint+or+uint8+or+uint16+or+uint32+or+uint64+or+float+or+float32+or+float64%5D"
    title="index_select[T; Idx: byte or char or SomeNumber](t: Tensor[T]; axis: int;
    indices: Tensor[Idx]): Tensor[T]"><wbr />index_<wbr />select<span class="attachedType"></span></a></li>

  </ul>
</li>
<li>
  <a class="reference reference-toplevel" href="#18" id="68">Templates</a>
  <ul class="simple simple-toc-section">
      <li><a class="reference" href="#bc.t%2C%2Cvarargs%5Bint%5D"
    title="bc(t: (Tensor | SomeNumber); shape: varargs[int]): untyped"><wbr />bc<span class="attachedType"></span></a></li>
  <li><a class="reference" href="#bc.t%2C%2CMetadataArray"
    title="bc(t: (Tensor | SomeNumber); shape: MetadataArray): untyped"><wbr />bc<span class="attachedType"></span></a></li>

  </ul>
</li>

</ul>

  </div>
  <div class="nine columns" id="content">
  <div id="tocRoot"></div>

  <p class="module-desc"></p>
  <div class="section" id="6">
<h1><a class="toc-backref" href="#6">Imports</a></h1>
<dl class="item">
<a class="reference external" href="metadataArray.html">metadataArray</a>, <a class="reference external" href="p_shapeshifting.html">p_shapeshifting</a>, <a class="reference external" href="p_checks.html">p_checks</a>, <a class="reference external" href="p_accessors_macros_write.html">p_accessors_macros_write</a>, <a class="reference external" href="accessors.html">accessors</a>, <a class="reference external" href="data_structure.html">data_structure</a>, <a class="reference external" href="init_cpu.html">init_cpu</a>, <a class="reference external" href="higher_order_applymap.html">higher_order_applymap</a>
</dl></div>
<div class="section" id="12">
<h1><a class="toc-backref" href="#12">Procs</a></h1>
<dl class="item">
<a id="transpose,Tensor"></a>
<dt><pre><span class="Keyword">proc</span> <a href="#transpose%2CTensor"><span class="Identifier">transpose</span></a><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noInit</span><span class="Other">,</span> <span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">inline</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

<p>Transpose a Tensor.</p>
<p>For N-d Tensor with shape (0, 1, 2 ... n-1) the resulting tensor will have shape (n-1, ... 2, 1, 0)</p>
<p>Data is not copied or modified, only metadata is modified.</p>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L27"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L27" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="asContiguous,Tensor[T],OrderType,bool"></a>
<dt><pre><span class="Keyword">proc</span> <a href="#asContiguous%2CTensor%5BT%5D%2COrderType%2Cbool"><span class="Identifier">asContiguous</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">layout</span><span class="Other">:</span> <span class="Identifier">OrderType</span> <span class="Other">=</span> <span class="Identifier">rowMajor</span><span class="Other">;</span> <span class="Identifier">force</span><span class="Other">:</span> <span class="Identifier">bool</span> <span class="Other">=</span> <span class="Identifier">false</span><span class="Other">)</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span>
    <span class="Identifier">T</span><span class="Other">]</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noInit</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

<p>Transform a tensor with general striding to a Tensor with contiguous layout.</p>
<p>By default tensor will be rowMajor.</p>
<p>The layout is kept if the tensor is already contiguous (C Major or F major) The &quot;force&quot; parameter can force re-ordering to a specific layout.</p>
<p>Result is always a fully packed tensor even if the input is a contiguous slice.</p>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L38"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L38" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="reshape,Tensor,varargs[int]"></a>
<dt><pre><span class="Keyword">proc</span> <a href="#reshape%2CTensor%2Cvarargs%5Bint%5D"><span class="Identifier">reshape</span></a><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">;</span> <span class="Identifier">new_shape</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noInit</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

Reshape a tensor. If possible no data copy is done and the returned tensor shares data with the input. If input is not contiguous, this is not possible and a copy will be made.<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a tensor</li>
<li>a new shape. Number of elements must be the same</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor with the same data but reshaped.</li>
</ul>
</dd>
</dl>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L59"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L59" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="reshape,Tensor,MetadataArray"></a>
<dt><pre><span class="Keyword">proc</span> <a href="#reshape%2CTensor%2CMetadataArray"><span class="Identifier">reshape</span></a><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">;</span> <span class="Identifier">new_shape</span><span class="Other">:</span> <a href="metadataArray.html#MetadataArray"><span class="Identifier">MetadataArray</span></a><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noInit</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

Reshape a tensor. If possible no data copy is done and the returned tensor shares data with the input. If input is not contiguous, this is not possible and a copy will be made.<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a tensor</li>
<li>a new shape. Number of elements must be the same</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor with the same data but reshaped.</li>
</ul>
</dd>
</dl>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L71"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L71" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="broadcast,Tensor[T],varargs[int]"></a>
<dt><pre><span class="Keyword">proc</span> <a href="#broadcast%2CTensor%5BT%5D%2Cvarargs%5Bint%5D"><span class="Identifier">broadcast</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noInit</span><span class="Other">,</span> <span class="Identifier">noSideEffect</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

<p>Explicitly broadcast a tensor to the specified shape.</p>
<p>Dimension(s) of size 1 can be expanded to arbitrary size by replicating values along that dimension.</p>
<dl class="docutils"><dt>Warning ⚠:</dt>
<dd>A broadcasted tensor should not be modified and only used for computation.</dd>
</dl>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L83"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L83" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="broadcast,Tensor[T],MetadataArray"></a>
<dt><pre><span class="Keyword">proc</span> <a href="#broadcast%2CTensor%5BT%5D%2CMetadataArray"><span class="Identifier">broadcast</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">shape</span><span class="Other">:</span> <a href="metadataArray.html#MetadataArray"><span class="Identifier">MetadataArray</span></a><span class="Other">)</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noInit</span><span class="Other">,</span> <span class="Identifier">noSideEffect</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

<p>Explicitly broadcast a tensor to the specified shape.</p>
<p>Dimension(s) of size 1 can be expanded to arbitrary size by replicating values along that dimension.</p>
<dl class="docutils"><dt>Warning ⚠:</dt>
<dd>A broadcasted tensor should not be modified and only used for computation.</dd>
</dl>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L95"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L95" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="broadcast,T,varargs[int]"></a>
<dt><pre><span class="Keyword">proc</span> <a href="#broadcast%2CT%2Cvarargs%5Bint%5D"><span class="Identifier">broadcast</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">val</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noInit</span><span class="Other">,</span>
    <span class="Identifier">noSideEffect</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

Broadcast a number<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a number to be broadcasted</li>
<li>a tensor shape that will be broadcasted to</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor with the broadcasted shape where all elements has the broadcasted value</li>
</ul>
</dd>
</dl>
<p>The broadcasting is made using tensor data of size 1 and 0 strides, i.e. the operation is memory efficient.</p>
<dl class="docutils"><dt>Warning ⚠:</dt>
<dd>A broadcasted tensor should not be modified and only used for computation. Modifying any value from this broadcasted tensor will change all its values.</dd>
</dl>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L107"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L107" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="broadcast,T,MetadataArray"></a>
<dt><pre><span class="Keyword">proc</span> <a href="#broadcast%2CT%2CMetadataArray"><span class="Identifier">broadcast</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">:</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">val</span><span class="Other">:</span> <span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">shape</span><span class="Other">:</span> <a href="metadataArray.html#MetadataArray"><span class="Identifier">MetadataArray</span></a><span class="Other">)</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noInit</span><span class="Other">,</span>
    <span class="Identifier">noSideEffect</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

Broadcast a number<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a number to be broadcasted</li>
<li>a tensor shape that will be broadcasted to</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor with the broadcasted shape where all elements has the broadcasted value</li>
</ul>
</dd>
</dl>
<p>The broadcasting is made using tensor data of size 1 and 0 strides, i.e. the operation is memory efficient.</p>
<dl class="docutils"><dt>Warning ⚠:</dt>
<dd>A broadcasted tensor should not be modified and only used for computation. Modifying any value from this broadcasted tensor will change all its values.</dd>
</dl>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L127"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L127" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="broadcast2,Tensor[T],Tensor[T]"></a>
<dt><pre><span class="Keyword">proc</span> <a href="#broadcast2%2CTensor%5BT%5D%2CTensor%5BT%5D"><span class="Identifier">broadcast2</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Keyword">tuple</span><span class="Other">[</span><span class="Identifier">a</span><span class="Other">,</span> <span class="Identifier">b</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">]</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noSideEffect</span><span class="Other">,</span> <span class="Identifier">noInit</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

<p>Broadcast 2 tensors so they have compatible shapes for element-wise computations.</p>
<p>Tensors in the tuple can be accessed with output.a and output.b</p>
<p>The returned broadcasted Tensors share the underlying data with the input.</p>
<p>Dimension(s) of size 1 can be expanded to arbitrary size by replicating values along that dimension.</p>
<dl class="docutils"><dt>Warning ⚠:</dt>
<dd>This is a no-copy operation, data is shared with the input. This proc does not guarantee that a <tt class="docutils literal"><span class="pre">let</span></tt> value is immutable. A broadcasted tensor should not be modified and only used for computation.</dd>
</dl>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L155"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L155" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="permute,Tensor,varargs[int]"></a>
<dt><pre><span class="Keyword">proc</span> <a href="#permute%2CTensor%2Cvarargs%5Bint%5D"><span class="Identifier">permute</span></a><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">;</span> <span class="Identifier">dims</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noInit</span><span class="Other">,</span> <span class="Identifier">noSideEffect</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

Permute dimensions of a tensors<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a tensor</li>
<li>the new dimension order</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor with re-order dimension</li>
</ul>
</dd>
<dt>Usage:</dt>
<dd><pre class="listing"><span class="Identifier">a</span><span class="Operator">.</span><span class="Identifier">permute</span><span class="Punctuation">(</span><span class="DecNumber">0</span><span class="Punctuation">,</span><span class="DecNumber">2</span><span class="Punctuation">,</span><span class="DecNumber">1</span><span class="Punctuation">)</span> <span class="Comment"># dim 0 stays at 0, dim 1 becomes dim 2 and dim 2 becomes dim 1</span></pre></dd>
</dl>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L176"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L176" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="concat,varargs[Tensor[T]],int"></a>
<dt><pre><span class="Keyword">proc</span> <a href="#concat%2Cvarargs%5BTensor%5BT%5D%5D%2Cint"><span class="Identifier">concat</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t_list</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">)</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noInit</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

Concatenate tensors<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>Tensors</li>
<li>An axis (dimension)</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor</li>
</ul>
</dd>
</dl>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L191"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L191" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="stack,varargs[Tensor[T]],Natural"></a>
<dt><pre><span class="Keyword">proc</span> <a href="#stack%2Cvarargs%5BTensor%5BT%5D%5D%2CNatural"><span class="Identifier">stack</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">tensors</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">Natural</span> <span class="Other">=</span> <span class="DecNumber">0</span><span class="Other">)</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noInit</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

Join a sequence of tensors along a new axis into a new tensor.<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a tensor</li>
<li>an axis (dimension)</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a new stacked tensor along the new axis</li>
</ul>
</dd>
</dl>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L256"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L256" class="link-seesrc" target="_blank" >Edit</a>

</dd>

</dl></div>
<div class="section" id="13">
<h1><a class="toc-backref" href="#13">Funcs</a></h1>
<dl class="item">
<a id="squeeze,AnyTensor"></a>
<dt><pre><span class="Keyword">func</span> <a href="#squeeze%2CAnyTensor"><span class="Identifier">squeeze</span></a><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="data_structure.html#AnyTensor"><span class="Identifier">AnyTensor</span></a><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">AnyTensor</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noInit</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

Squeeze tensors. For example a Tensor of shape [4,1,3] will become [4,3]<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a tensor</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor with singleton dimensions collapsed</li>
</ul>
</dd>
</dl>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L226"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L226" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="squeeze,Tensor,Natural"></a>
<dt><pre><span class="Keyword">func</span> <a href="#squeeze%2CTensor%2CNatural"><span class="Identifier">squeeze</span></a><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">Natural</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noInit</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

Collapse the given axis, if the dimension is not 1, it does nothing.<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a tensor</li>
<li>an axis (dimension)</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor with that axis collapsed, if it was a singleton dimension</li>
</ul>
</dd>
</dl>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L235"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L235" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="unsqueeze,Tensor,Natural"></a>
<dt><pre><span class="Keyword">func</span> <a href="#unsqueeze%2CTensor%2CNatural"><span class="Identifier">unsqueeze</span></a><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">Natural</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">Tensor</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noInit</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

Insert a new axis just before the given axis, increasing the tensor dimension (rank) by 1<dl class="docutils"><dt>Input:</dt>
<dd><ul class="simple"><li>a tensor</li>
<li>an axis (dimension)</li>
</ul>
</dd>
<dt>Returns:</dt>
<dd><ul class="simple"><li>a tensor with that new axis</li>
</ul>
</dd>
</dl>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L245"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L245" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="split,Tensor[T],Positive,Natural"></a>
<dt><pre><span class="Keyword">func</span> <a href="#split%2CTensor%5BT%5D%2CPositive%2CNatural"><span class="Identifier">split</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">chunk_size</span><span class="Other">:</span> <span class="Identifier">Positive</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">Natural</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">seq</span><span class="Other">[</span><a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">]</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma">
    <span class="Identifier">noInit</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

Split the tensor into chunks of size <tt class="docutils literal"><span class="pre">chunk_size</span></tt> along the specified axis. Last chunk size will equal the remainder if the specified axis length is not divisible by <tt class="docutils literal"><span class="pre">chunk_size</span></tt>
&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L266"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L266" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="chunk,Tensor[T],Positive,Natural"></a>
<dt><pre><span class="Keyword">func</span> <a href="#chunk%2CTensor%5BT%5D%2CPositive%2CNatural"><span class="Identifier">chunk</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">nb_chunks</span><span class="Other">:</span> <span class="Identifier">Positive</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">Natural</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">seq</span><span class="Other">[</span><a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">]</span> <span><span class="Other">{</span><span class="Other pragmadots">...</span><span class="Other">}</span></span><span class="pragmawrap"><span class="Other">{.</span><span class="pragma"><span class="Identifier">noInit</span></span><span class="Other">.}</span></span></pre></dt>
<dd>

<p>Splits a Tensor into n chunks along the specified axis.</p>
<p>In case a tensor cannot be split evenly, with la == length_axis, n = n_chunks</p>
<dl class="docutils"><dt>it returns la mod n subtensors of size <tt class="docutils literal"><span class="pre">(la div n) + 1</span></tt></dt>
<dd>the rest of size <tt class="docutils literal"><span class="pre">la div n</span></tt>.</dd>
</dl>
<p>This is consistent with numpy array_split</p>

&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L282"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L282" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="index_select,Tensor[T],int,Tensor[Idx: byte or char or int or int8 or int16 or int32 or int64 or uint or uint8 or uint16 or uint32 or uint64 or float or float32 or float64]"></a>
<dt><pre><span class="Keyword">func</span> <a href="#index_select%2CTensor%5BT%5D%2Cint%2CTensor%5BIdx%3A+byte+or+char+or+int+or+int8+or+int16+or+int32+or+int64+or+uint+or+uint8+or+uint16+or+uint32+or+uint64+or+float+or+float32+or+float64%5D"><span class="Identifier">index_select</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">;</span> <span class="Identifier">Idx</span><span class="Other">:</span> <span class="Identifier">byte</span> <span class="Keyword">or</span> <span class="Identifier">char</span> <span class="Keyword">or</span> <span class="Identifier">SomeNumber</span><span class="Other">]</span><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span><span class="Other">;</span> <span class="Identifier">axis</span><span class="Other">:</span> <span class="Identifier">int</span><span class="Other">;</span>
    <span class="Identifier">indices</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">Idx</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a><span class="Other">[</span><span class="Identifier">T</span><span class="Other">]</span></pre></dt>
<dd>

Take elements from a tensor along an axis using the indices Tensor. This is equivalent to NumPy <tt class="docutils literal"><span class="pre">take</span></tt>. The result does not share the input storage, there are copies. The tensors containing the indices can be an integer, byte or char tensor.
&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L303"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L303" class="link-seesrc" target="_blank" >Edit</a>

</dd>

</dl></div>
<div class="section" id="18">
<h1><a class="toc-backref" href="#18">Templates</a></h1>
<dl class="item">
<a id="bc.t,,varargs[int]"></a>
<dt><pre><span class="Keyword">template</span> <a href="#bc.t%2C%2Cvarargs%5Bint%5D"><span class="Identifier">bc</span></a><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Other">(</span><a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a> <span class="Operator">|</span> <span class="Identifier">SomeNumber</span><span class="Other">)</span><span class="Other">;</span> <span class="Identifier">shape</span><span class="Other">:</span> <span class="Identifier">varargs</span><span class="Other">[</span><span class="Identifier">int</span><span class="Other">]</span><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">untyped</span></pre></dt>
<dd>

Alias for <tt class="docutils literal"><span class="pre">broadcast</span></tt>
&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L147"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L147" class="link-seesrc" target="_blank" >Edit</a>

</dd>
<a id="bc.t,,MetadataArray"></a>
<dt><pre><span class="Keyword">template</span> <a href="#bc.t%2C%2CMetadataArray"><span class="Identifier">bc</span></a><span class="Other">(</span><span class="Identifier">t</span><span class="Other">:</span> <span class="Other">(</span><a href="data_structure.html#Tensor"><span class="Identifier">Tensor</span></a> <span class="Operator">|</span> <span class="Identifier">SomeNumber</span><span class="Other">)</span><span class="Other">;</span> <span class="Identifier">shape</span><span class="Other">:</span> <a href="metadataArray.html#MetadataArray"><span class="Identifier">MetadataArray</span></a><span class="Other">)</span><span class="Other">:</span> <span class="Identifier">untyped</span></pre></dt>
<dd>

Alias for <tt class="docutils literal"><span class="pre">broadcast</span></tt>
&nbsp;&nbsp;<a
href="https://github.com/mratsim/arraymancer/tree/version-1-0/src/tensor/shapeshifting.nim#L151"
class="link-seesrc" target="_blank">Source</a>
<a href="https://github.com/mratsim/arraymancer/edit/master/src/tensor/shapeshifting.nim#L151" class="link-seesrc" target="_blank" >Edit</a>

</dd>

</dl></div>

  </div>
</div>

    <div class="row">
      <div class="twelve-columns footer">
        <span class="nim-sprite"></span>
        <br/>
        <small>Made with Nim. Generated: 2020-01-08 23:30:58 UTC</small>
      </div>
    </div>
  </div>
</article>
</body>
</html>
